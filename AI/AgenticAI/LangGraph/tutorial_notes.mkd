# Module 0 Notes

## API Key Setup

Sign up for LangSmith

Sign up here. You can reference LangSmith docs here.

Then, set

LANGCHAIN_API_KEY
LANGCHAIN_TRACING_V2=true
in your environment.

Set up OpenAI API key

If you don’t have an OpenAI API key, you can sign up here.

Then, set

OPENAI_API_KEY
in your environment.

Tavily for web search

Tavily Search API is a search engine optimized for LLMs and RAG, aimed at efficient, quick, and persistent search results. You can sign up for an API key here. It’s easy to sign up and offers a generous free tier. Some lessons in Module 4 will use Tavily.

Then, set

TAVILY_API_KEY
in your environment.

## Software Setup
Set up LangGraph Studio

Currently, LangGraph Studio is only compatible with macOS. Additionally, if you plan to use the notebooks in Google Colab, skip the LangGraph Studio portions (they will not run).

Download the latest .dmg file here. Then, install Docker Desktop for Mac here.

Graphs for LangGraph Studio are in the module-x/studio/ folders. To use LangGraph Studio, you will need to create a .env file with the relevant API keys. Run this from the command line to create these files for Module 1 to 4. As an example:

$ for i in {1..4}; do
cp module-$i/studio/.env.example module-$i/studio/.env
echo "OPENAI_API_KEY=\"$OPENAI_API_KEY\"" > module-$i/studio/.env
done
echo "TAVILY_API_KEY=\"$TAVILY_API_KEY\"" >> module-4/studio/.env

## Model Parameters

In tutorial using Open AI Models but basic properties are the same

[Runable Interface](https://python.langchain.com/v0.2/docs/concepts/#runnable-interface) api used


ChatModels:
- model: the name of the model
- temperature: the sampling temperature
    - controls the randomness or creativity of the model's output where low temperature (close to 0) is more deterministic and focused outputs. This is good for tasks requiring accuracy or factual responses. High temperature (close to 1) is good for creative tasks or generating varied responses. 
- timeout: request timeout
- max_tokens: max tokens to generate
- stop: default stop sequences
- max_retries: max number of times to retry requests
- api_key: API key for the model provider
- base_url: endpoint to send requests to

# Module 1 Notes


## Introduction and Basics
Solitary languege models are lmited
- no access to tools, external sources, multi-step owrkflows etc...

Chains: control flows before and after LLM calls
- tool calls, retrieval, etc..
- Flow controls create chains
    - Reliable as it is the same flow every time

Agents: control flow defined by an LLM
- Many kinds of agents
    - Router picks between a set series of control flows - LLM has narrow set of options and less control
    - Fully autonomous, can generate its own next move - LLM as wide set of options and more control
- Typically level of control is inversely proportional to reliability
    - Langraph bends the curve to increase reliability wit llm control
    - Langgraph balances reliability with control

LangGraph
- Lets developer sets part of control flow in advance
- Express control flows as graphs
- Pillars
    - Persistence, Streaming, Human-in-the-loop, Controlability
- Can use Langchain LLMs and VectorStores

## Simple Graph

Edges
- Connect Nodes
- Normal Edge:  Always progressed the same i.e. Start to Node 1
- Conditinal Edge: Branching options i.e. Node1 can go to Node2 or Node 3

State
- Inpur for all nodes ande edges of the graph

Nodes
- Python functions
- first parameter is the state

Graph
- Brings everything together
- First add nodes